{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - Answering with Retrieval\n",
    "\n",
    "ë³¸ ëŒ€íšŒì˜ ê³¼ì œëŠ” ì¤‘ì•™ì •ë¶€ ì¬ì • ì •ë³´ì— ëŒ€í•œ **ê²€ìƒ‰ ê¸°ëŠ¥**ì„ ê°œì„ í•˜ê³  í™œìš©ë„ë¥¼ ë†’ì´ëŠ” ì§ˆì˜ì‘ë‹µ ì•Œê³ ë¦¬ì¦˜ì„ ê°œë°œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. <br>ì´ë¥¼ í†µí•´ ë°©ëŒ€í•œ ì¬ì • ë°ì´í„°ë¥¼ ì¼ë°˜ êµ­ë¯¼ê³¼ ì „ë¬¸ê°€ ëª¨ë‘ê°€ ì‰½ê²Œ ì ‘ê·¼í•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤. <br><br>\n",
    "ë² ì´ìŠ¤ë¼ì¸ì—ì„œëŠ” í‰ê°€ ë°ì´í„°ì…‹ë§Œì„ í™œìš©í•˜ì—¬ source pdf ë§ˆë‹¤ Vector DBë¥¼ êµ¬ì¶•í•œ ë’¤ langchain ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ llama-2-ko-7b ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ RAG í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•´ ì¶”ë¡ í•˜ëŠ” ê³¼ì •ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. <br>( train_setì„ í™œìš©í•œ í›ˆë ¨ ê³¼ì •ì€ í¬í•¨í•˜ì§€ ì•Šìœ¼ë©°, test_set  ì— ëŒ€í•œ ì¶”ë¡ ë§Œ ì§„í–‰í•©ë‹ˆë‹¤. )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!pip install accelerate\n",
    "!pip install -i https://pypi.org/simple/ bitsandbytes\n",
    "!pip install transformers[torch] -U\n",
    "\n",
    "!pip install datasets\n",
    "!pip install langchain\n",
    "!pip install langchain_community\n",
    "!pip install PyMuPDF\n",
    "!pip install sentence-transformers\n",
    "# !pip install faiss-gpu\n",
    "!pip install faiss-cpu\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import fitz  # PyMuPDF\n",
    "import pickle\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "from accelerate import Accelerator\n",
    "\n",
    "\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from datasets import load_dataset\n",
    "\n",
    "#LORA\n",
    "from peft import LoraConfig, PeftModel\n",
    "\n",
    "# Langchain ê´€ë ¨\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(file_path, chunk_size=800, chunk_overlap=50):\n",
    "    \"\"\"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ chunk ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°\"\"\"\n",
    "    # PDF íŒŒì¼ ì—´ê¸°\n",
    "    doc = fitz.open(file_path)\n",
    "    text = ''\n",
    "    # ëª¨ë“  í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    # í…ìŠ¤íŠ¸ë¥¼ chunkë¡œ ë¶„í• \n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunk_temp = splitter.split_text(text)\n",
    "    # Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "    chunks = [Document(page_content=t) for t in chunk_temp]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def create_vector_db(chunks, model_path=\"intfloat/multilingual-e5-small\"):\n",
    "    \"\"\"FAISS DB ìƒì„±\"\"\"\n",
    "    # ì„ë² ë”© ëª¨ë¸ ì„¤ì •\n",
    "    model_kwargs = {'device': 'cuda'}\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_path,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "    # FAISS DB ìƒì„± ë° ë°˜í™˜\n",
    "    db = FAISS.from_documents(chunks, embedding=embeddings)\n",
    "    return db\n",
    "\n",
    "def normalize_path(path):\n",
    "    \"\"\"ê²½ë¡œ ìœ ë‹ˆì½”ë“œ ì •ê·œí™”\"\"\"\n",
    "    return unicodedata.normalize('NFC', path)\n",
    "\n",
    "\n",
    "def process_pdfs_from_dataframe(df, base_directory):\n",
    "    \"\"\"ë”•ì…”ë„ˆë¦¬ì— pdfëª…ì„ í‚¤ë¡œí•´ì„œ DB, retriever ì €ì¥\"\"\"\n",
    "    pdf_databases = {}\n",
    "    unique_paths = df['Source_path'].unique()\n",
    "    \n",
    "    for path in tqdm(unique_paths, desc=\"Processing PDFs\"):\n",
    "        # ê²½ë¡œ ì •ê·œí™” ë° ì ˆëŒ€ ê²½ë¡œ ìƒì„±\n",
    "        normalized_path = normalize_path(path)\n",
    "        full_path = os.path.normpath(os.path.join(base_directory, normalized_path.lstrip('./'))) if not os.path.isabs(normalized_path) else normalized_path\n",
    "        \n",
    "        pdf_title = os.path.splitext(os.path.basename(full_path))[0]\n",
    "        print(f\"Processing {pdf_title}...\")\n",
    "        \n",
    "        # PDF ì²˜ë¦¬ ë° ë²¡í„° DB ìƒì„±\n",
    "        chunks = process_pdf(full_path)\n",
    "        db = create_vector_db(chunks)\n",
    "        \n",
    "        # Retriever ìƒì„±\n",
    "        retriever = db.as_retriever(search_type=\"mmr\", \n",
    "                                    search_kwargs={'k': 3, 'fetch_k': 8})\n",
    "        \n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        pdf_databases[pdf_title] = {\n",
    "                'db': db,\n",
    "                'retriever': retriever\n",
    "        }\n",
    "    return pdf_databases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:   0%|          | 0/9 [00:00<?, ?it/s]c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€_í˜ì‹ ì°½ì—…ì‚¬ì—…í™”ìê¸ˆ(ìœµì)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  11%|â–ˆ         | 1/9 [00:04<00:36,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ë³´ê±´ë³µì§€ë¶€_ë¶€ëª¨ê¸‰ì—¬(ì˜ì•„ìˆ˜ë‹¹) ì§€ì›...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  22%|â–ˆâ–ˆâ–       | 2/9 [00:08<00:29,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ë³´ê±´ë³µì§€ë¶€_ë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ ì‚¬ì—…ìš´ì˜...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  33%|â–ˆâ–ˆâ–ˆâ–      | 3/9 [00:12<00:24,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ì‚°ì—…í†µìƒìì›ë¶€_ì—ë„ˆì§€ë°”ìš°ì²˜...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:17<00:21,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing êµ­í† êµí†µë¶€_í–‰ë³µì£¼íƒì¶œì...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:21<00:16,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ã€ŒFIS ì´ìŠˆ & í¬ì»¤ìŠ¤ã€ 22-4í˜¸ ã€Šì¤‘ì•™-ì§€ë°© ê°„ ì¬ì •ì¡°ì •ì œë„ã€‹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:26<00:14,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ã€ŒFIS ì´ìŠˆ & í¬ì»¤ìŠ¤ã€ 23-2í˜¸ ã€Ší•µì‹¬ì¬ì •ì‚¬ì—… ì„±ê³¼ê´€ë¦¬ã€‹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:32<00:10,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ã€ŒFIS ì´ìŠˆ&í¬ì»¤ìŠ¤ã€ 22-2í˜¸ ã€Šì¬ì •ì„±ê³¼ê´€ë¦¬ì œë„ã€‹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:37<00:05,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ã€ŒFIS ì´ìŠˆ & í¬ì»¤ìŠ¤ã€(ì‹ ê·œ) í†µê¶Œ ì œ1í˜¸ ã€Šìš°ë°œë¶€ì±„ã€‹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:43<00:00,  4.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf_databasesê°€ pickle íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "base_directory = './' # Your Base Directory\n",
    "df = pd.read_csv('./test.csv')\n",
    "pdf_databases = process_pdfs_from_dataframe(df, base_directory)\n",
    "\n",
    "# PDF ë°ì´í„°ë² ì´ìŠ¤ë¥¼ pickle íŒŒì¼ë¡œ ì €ì¥\n",
    "with open('pdf_databases_cpu.pickle', 'wb') as f:\n",
    "    pickle.dump(pdf_databases, f)\n",
    "\n",
    "print(\"pdf_databasesê°€ pickle íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "base_directory = './' # Your Base Directory\n",
    "df = pd.read_csv('./test.csv')\n",
    "with open('pdf_databases_cpu.pickle', 'rb') as f:\n",
    "    pdf_databases = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_layers(model):\n",
    "    # ëª¨ë¸ì˜ ëª¨ë“  ë ˆì´ì–´ ì´ë¦„ê³¼ êµ¬ì¡° ì¶œë ¥\n",
    "    for name, module in model.named_modules():\n",
    "        print(f\"{name}: {module}\")\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "model_id = \"beomi/llama-2-ko-7b\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "# ë ˆì´ì–´ ì´ë¦„ê³¼ êµ¬ì¡° ì¶œë ¥\n",
    "print_model_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì • ë ˆì´ì–´ ë™ê²° ë° í•™ìŠµ ê°€ëŠ¥ ì„¤ì •\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_layers(model):\n",
    "    # ëª¨ë¸ì˜ ëª¨ë“  ë ˆì´ì–´ ì¶œë ¥\n",
    "    for name, module in model.named_modules():\n",
    "        print(f\"{name}: {module}\")\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ í›„ ë ˆì´ì–´ ì¶œë ¥\n",
    "model = AutoModelForCausalLM.from_pretrained(\"beomi/gemma-ko-2b\")\n",
    "print_model_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸°ê¸ˆì´ ì˜ˆì‚°ê³¼ ë‹¤ë¥¸ ì ì€?\n",
      "ê¸°ê¸ˆì€ ì˜ˆì‚°ê³¼ êµ¬ë¶„ë˜ëŠ” ì¬ì •ìˆ˜ë‹¨ìœ¼ë¡œì„œ ì¬ì •ìš´ì˜ì˜ ì‹ ì¶•ì„±ì„ ê¸°í•  í•„ìš”ê°€ ìˆì„ ë•Œ, ì •ë¶€ê°€ í¸ì„±í•˜ê³  êµ­íšŒì—ì„œ ì‹¬ì˜ãƒ»ì˜ê²°í•œ ê¸°ê¸ˆìš´ìš©ê³„íšì— ì˜í•´ ìš´ìš©ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mydf = pd.read_csv(\"stf_train.csv\")\n",
    "print(mydf[\"Question\"][2])\n",
    "print(mydf[\"Answer\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_llm_SFTTrainer():\n",
    "    # 4ë¹„íŠ¸ ì–‘ìí™” ì„¤ì •\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "\n",
    "    # ëª¨ë¸ ID \n",
    "    #model_id = \"beomi/gemma-ko-2b\"\n",
    "    model_id = \"beomi/llama-2-ko-7b\"\n",
    "    # í† í¬ë‚˜ì´ì € ë¡œë“œ ë° ì„¤ì •\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    tokenizer.use_default_system_prompt = False\n",
    "\n",
    "    # ëª¨ë¸ ë¡œë“œ ë° ì–‘ìí™” ì„¤ì • ì ìš©\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Load LoRA configuration\n",
    "    peft_config = LoraConfig(\n",
    "        r=16,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )        \n",
    "        \n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        num_train_epochs=3,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        save_steps=1000,\n",
    "        evaluation_strategy=\"steps\"\n",
    "    )\n",
    "\n",
    "\n",
    "    #dataset\n",
    "    train_dataset = load_dataset('csv', data_files='stf_train.csv')['train']\n",
    "    eval_dataset = load_dataset('csv', data_files='stf_eval.csv')['train']  \n",
    "    \n",
    "    def formatting_prompts_func(example):\n",
    "        output_texts = []\n",
    "        for i in range(len(example)):\n",
    "            text = \"\"\"\n",
    "ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì—­í• ì„ í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì˜¬ë°”ë¥¸ ë‹µë³€ì„ í•˜ì„¸ìš”.\n",
    "ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”\n",
    "[ì •ë³´]\n",
    "{example[Context]}\n",
    "\n",
    "ì§ˆë¬¸: {example[Question]}\n",
    "ë‹µë³€: {example[Answer]}\n",
    "\"\"\"\n",
    "            output_texts.append(text)\n",
    "        return output_texts\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        peft_config = peft_config,\n",
    "        formatting_func=formatting_prompts_func,\n",
    "        train_dataset = train_dataset,\n",
    "        eval_dataset = eval_dataset,   \n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    trainer.train()\n",
    "\n",
    "    finetuned_model = \"finetuned_model\"\n",
    "    # Save trained model\n",
    "    trainer.model.save_pretrained(finetuned_model)\n",
    "    \n",
    "    text_generation_pipeline = pipeline(\n",
    "        model=trainer.model,\n",
    "        tokenizer=tokenizer,\n",
    "        task=\"text-generation\",\n",
    "        temperature=0.2,\n",
    "        return_full_text=False,\n",
    "        max_new_tokens=128,\n",
    "        #repetition_penalty=1.5\n",
    "    )\n",
    "\n",
    "    hf = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "    return hf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:12<00:00,  1.20it/s]\n",
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:289: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "Map:   0%|          | 0/496 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 496/496 [00:00<00:00, 27555.00 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 397/397 [00:00<00:00, 26464.80 examples/s]\n",
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:408: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:603: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.30it/s]\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 4.6012, 'train_samples_per_second': 1.956, 'train_steps_per_second': 1.304, 'train_loss': 6.471307118733724, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# LLM íŒŒì´í”„ë¼ì¸\n",
    "llm = setup_llm_SFTTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "base_directory = './' # Your Base Directory\n",
    "df = pd.read_csv('./test.csv')\n",
    "with open('pdf_databases_cpu.pickle', 'rb') as f:\n",
    "    pdf_databases = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain ì„ ì´ìš©í•œ ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering Questions:   0%|          | 0/49 [00:00<?, ?it/s]c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 2022ë…„ í˜ì‹ ì°½ì—…ì‚¬ì—…í™”ìê¸ˆ(ìœµì)ì˜ ì˜ˆì‚°ì€ ì–¼ë§ˆì¸ê°€ìš”?\n",
      "Answer: 2022ë…„ í˜ì‹ ì°½ì—…ì‚¬ì—…í™”ìê¸ˆ(ìœµì)ì˜ ì˜ˆì‚°ì€ 2ì¡° 78ì–µì›ì…ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€ì˜ í˜ì‹ ì°½ì—…ì‚¬ì—…í™”ìê¸ˆ(ìœµì) ì‚¬ì—…ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:   2%|â–         | 1/49 [01:57<1:34:09, 117.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€ì˜ í˜ì‹ ì°½ì—…ì‚¬ì—…í™”ìê¸ˆ(ìœµì) ì‚¬ì—…ì€ ì°½ì—…ê¸°ì—…ì— ëŒ€í•œ ìœµì ë° ë³´ì¦, ê¸°ìˆ ê°œë°œ ë° ì‚¬ì—…í™” ì§€ì›, ì°½ì—…ë³´ìœ¡ì„¼í„° ì§€ì›, ì°½ì—…ê¸°ì—…ì— ëŒ€í•œ íˆ¬ìì§€ì›, ì°½ì—…ê¸°ì—…ì— ëŒ€í•œ í•´ì™¸ì§„ì¶œ ì§€ì›, ì°½ì—…ê¸°ì—…ì— ëŒ€í•œ ì°½ì—…ì§€ì› ì¸í”„ë¼ êµ¬ì¶• ë° ì°½ì—…ê¸°ì—…ì— ëŒ€í•œ ì°½ì—…ì§€ì› ì¸í”„ë¼ êµ¬ì¶• ë° ì°½ì—…ê¸°ì—…ì— ëŒ€í•œ ì°½ì—…ì§€ì› ì¸í”„ë¼ êµ¬ì¶• ë° ì°½ì—…ê¸°ì—…ì— ëŒ€í•œ ì°½ì—…ì§€ì› ì¸í”„ë¼ êµ¬ì¶• ë° ì°½ì—…ê¸°ì—…ì— ëŒ€í•œ ì°½ì—…ì§€ì› ì¸í”„ë¼ êµ¬ì¶• ë° ì°½ì—…ê¸°ì—…ì— ëŒ€í•œ ì°½ì—…ì§€ì› ì¸í”„ë¼ êµ¬ì¶• ë° ì°½ì—…ê¸°ì—…ì— ëŒ€í•œ ì°½ì—…ì§€ì› ì¸í”„ë¼ êµ¬ì¶• ë° ì°½ì—…ê¸°ì—…ì— ëŒ€í•œ ì°½ì—…ì§€ì› ì¸í”„ë¼ êµ¬ì¶• ë° ì°½ì—…ê¸°ì—…ì— ëŒ€í•œ\n",
      "\n",
      "Question: ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€ì˜ í˜ì‹ ì°½ì—…ì‚¬ì—…í™”ìê¸ˆ(ìœµì) ì‚¬ì—…ê·¼ê±°ëŠ” ì–´ë–¤ ë²•ë¥ ì— ê·¼ê±°í•˜ê³  ìˆë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì¤‘ì†Œê¸°ì—…ì§„í¥ì— ê´€í•œ ë²•ë¥  ì œ66ì¡°, ì œ67ì¡°, ì œ74ì¡°â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: 2010ë…„ì— ì‹ ê·œ ì§€ì›ëœ í˜ì‹ ì°½ì—…ì‚¬ì—…í™”ìê¸ˆì€ ë¬´ì—‡ì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:   4%|â–         | 2/49 [03:53<1:31:14, 116.48s/it]c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2010ë…„ 1ì›” 1ì¼ë¶€í„° 2014ë…„ 12ì›” 31ì¼ê¹Œì§€ 4ë…„ê°„ ì§€ì›ëœ ì‚¬ì—…ì…ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: í˜ì‹ ì°½ì—…ì‚¬ì—…í™”ìê¸ˆ ì¤‘ 2020ë…„ì— ì‹ ê·œ ì§€ì›ëœ ìê¸ˆì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "Answer: 2020ë…„ í˜ì‹ ì°½ì—…ì‚¬ì—…í™”ìê¸ˆ ì‹ ê·œ ì§€ì› ì‚¬ì—…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¬ì°½ì—…ìê¸ˆì´ ì¬ë„ì•½ì§€ì›ìê¸ˆìœ¼ë¡œ ì´ê´€ëœ ì—°ë„ëŠ” ì–¸ì œì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:   6%|â–Œ         | 3/49 [05:48<1:28:59, 116.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2014ë…„ 1ì›” 1ì¼ë¶€í„° ì¬ì°½ì—…ìê¸ˆì„ ì¬ë„ì•½ì§€ì›ìê¸ˆìœ¼ë¡œ ì´ê´€í•˜ì˜€ìŠµë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì°½ì—…ê¸°ë°˜ì§€ì›ê³¼ ì‹ ì²­ ëŒ€ìƒì´ ì¤‘ë³µì¸ ìê¸ˆì´ ì–´ë–¤ ê²ƒì´ë©°, ì´ ìê¸ˆì´ íì§€ëœ ì—°ë„ëŠ” ì–¸ì œì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì°½ì—…ê¸°ë°˜ì§€ì›ê³¼ ì‹ ì²­ ëŒ€ìƒì´ ì¤‘ë³µì¸ ìê¸ˆì€ ì°½ì—…ì§€ì›ìê¸ˆ(ìœµì)ì…ë‹ˆë‹¤.â€‹ì°½ì—…ì§€ì›ìê¸ˆì€ ì°½ì—…ê¸°ì—…ì§€ì›ìê¸ˆ(ìœµì)ì˜ ë‚´ì—­ì‚¬ì—…ìœ¼ë¡œ 2023ë…„ íì§€ë  ì˜ˆì •ì…ë‹ˆë‹¤.â€‹ì°½ì—…ì§€ì›ìê¸ˆì€ ì°½ì—…ê¸°ì—…ì§€ì›ìê¸ˆ(ìœµì)ì˜ ë‚´ì—­ì‚¬ì—…ìœ¼ë¡œ 2023ë…„ íì§€ë  ì˜ˆì •ì…ë‹ˆë‹¤.â€‹ì°½ì—…ì§€ì›ìê¸ˆì€ ì°½ì—…ê¸°ì—…ì§€ì›ìê¸ˆ(ìœµì)ì˜ ë‚´ì—­ì‚¬ì—…ìœ¼ë¡œ 2023ë…„ íì§€ë  ì˜ˆì •ì…ë‹ˆë‹¤.â€‹ì°½ì—…ì§€ì›ìê¸ˆì€ ì°½ì—…ê¸°ì—…ì§€ì›ìê¸ˆ(ìœµì)ì˜ ë‚´ì—­ì‚¬ì—…ìœ¼ë¡œ 2023ë…„\n",
      "\n",
      "Question: í˜ì‹ ì°½ì—…ì‚¬ì—…í™”ìê¸ˆ(ìœµì) ì‚¬ì—…ì„ ì‹œí–‰í•˜ëŠ” ì£¼ì²´ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:   8%|â–Š         | 4/49 [07:44<1:26:48, 115.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì‚¬ì—…ì˜ ì‹œí–‰ì£¼ì²´ëŠ” ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ì§„í¥ê³µë‹¨ì…ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: í˜ì‹ ì°½ì—…ì‚¬ì—…í™”ìê¸ˆ(ìœµì) ì‚¬ì—… ì§‘í–‰ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì‚¬ì—…ê³„íšìˆ˜ë¦½/ê³µê³ â€‹(ì¤‘ê¸°ë¶€, ì¤‘ì§„ê³µ)â€‹â‡¨ì‚¬ì „ìƒë‹´ ë° ì‹ ì²­Â·ì ‘ìˆ˜â€‹(ì¤‘ì†Œê¸°ì—… â†’ì¤‘ì§„ê³µ)â€‹â‡¨â€‹ì„œë¥˜ ë° í˜„ì¥ì‹¤ì‚¬â€‹(ì¤‘ì§„ê³µ â†’ì¤‘ì†Œê¸°ì—…)â€‹â‡¦â€‹ìœµì ì‹¤í–‰â€‹(ì¤‘ì§„ê³µ, ì€í–‰ â†’ì¤‘ì†Œê¸°ì—…)â€‹â‡¦â€‹ì§€ì›ê²°ì •í†µë³´â€‹(ì¤‘ì§„ê³µ â†’ì¤‘ì†Œê¸°ì—…)â€‹â‡¦â€‹í‰ê°€ ë° ìŠ¹ì¸â€‹(ì¤‘ì§„ê³µ â†’ì¤‘ì†Œê¸°ì—…)â€‹- 2006. 1â€‹ì§€ì›ëŒ€ìƒì„ ì—…ë ¥ \n",
      "\n",
      "Question: ë¶€ëª¨ê¸‰ì—¬ ì§€ì› ì‚¬ì—…ì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  10%|â–ˆ         | 5/49 [09:27<1:21:34, 111.24s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ë¶€ëª¨ê¸‰ì—¬ ì§€ì› ì‚¬ì—…ì€ ì¶œì‚° ë° ì–‘ìœ¡ìœ¼ë¡œ ì†ì‹¤ë˜ëŠ” ì†Œë“ì„ ë³´ì „í•˜ê³ , ì£¼ ì–‘ìœ¡ìì˜ ì§ì ‘ëŒë´„ì´ ì¤‘ìš”í•œ ì•„ë™ë°œë‹¬ì˜ íŠ¹ì„±ì— ë”°ë¼ ì˜ì•„ê¸° ëŒë´„ì„ ë‘í…ê²Œ ì§€ì›í•˜ê¸° ìœ„í•´ ë¶€ëª¨ê¸‰ì—¬ ì§€ê¸‰í•˜ëŠ” ì‚¬ì—…ì…ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ë¶€ëª¨ê¸‰ì—¬(ì˜ì•„ìˆ˜ë‹¹)ì˜ 2024ë…„ í™•ì •ëœ ì˜ˆì‚°ì€ ëª‡ë°±ë§Œì›ì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2024ë…„ ì¤‘ì•™ì •ë¶€ì˜ ì˜ˆì‚°ì€ ì¼ë°˜íšŒê³„ 1ê°œ, íŠ¹ë³„íšŒê³„ 21ê°œ, ê¸°ê¸ˆ 68ê°œë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ë¶€ëª¨ê¸‰ì—¬ ì§€ì› ì‚¬ì—…ì€ ì–´ë–¤ ë²•ë ¹ìƒ ê·¼ê±°ë¥¼ ê°–ê³  ì¶”ì§„ë˜ê³  ìˆë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  12%|â–ˆâ–        | 6/49 [10:57<1:14:36, 104.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì•„ë™ìˆ˜ë‹¹ë²• ì œ4ì¡°ì œ5í•­ì— ê·¼ê±°í•˜ì—¬ ì¶”ì§„ë˜ê³  ìˆìŠµë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì˜ì•„ìˆ˜ë‹¹ ë„ì…ì— ëŒ€í•œ ì¶”ì§„ê²½ìœ„ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2020ë…„ 12ì›” 31ì¼ ì˜ì•„ìˆ˜ë‹¹ ë„ì…ì„ ìœ„í•œ ì˜ˆë¹„íƒ€ë‹¹ì„±ì¡°ì‚¬ê°€ í†µê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ë¶€ëª¨ê¸‰ì—¬ ì§€ì›ì‚¬ì—…ì€ ì–¸ì œë¶€í„° ì‹œí–‰ë˜ì—ˆë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  14%|â–ˆâ–        | 7/49 [12:27<1:09:37, 99.47s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ë¶€ëª¨ê¸‰ì—¬ ì§€ì›ì‚¬ì—…ì€ 2022ë…„ 1ì›” 1ì¼ë¶€í„° ì‹œí–‰ë©ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ë³´ê±´ë³µì§€ë¶€ì˜ ë¶€ëª¨ê¸‰ì—¬(ì˜ì•„ìˆ˜ë‹¹) ì§€ì› ì‚¬ì—…ì‹œí–‰ë°©ë²•ì€ ë¬´ì—‡ì´ë©°, ì‚¬ì—… ìˆ˜í˜œìëŠ” ëˆ„êµ¬ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ë¶€ëª¨ê¸‰ì—¬(ì˜ì•„ìˆ˜ë‹¹) ì§€ì› ì‚¬ì—…ì€ ë³´ê±´ë³µì§€ë¶€ ì†Œê´€ ì¤‘ì•™ì •ë¶€ ì¬ì •ì²´ê³„ì˜ ì¼ë°˜íšŒê³„ì™€ íŠ¹ë³„íšŒê³„, ê¸°ê¸ˆì˜ 21ê°œ íŠ¹ë³„íšŒê³„, 68ê°œ ê¸°ê¸ˆ ì¤‘ 21ê°œ íŠ¹ë³„íšŒê³„ì™€ 68ê°œ ê¸°ê¸ˆì˜ 3143-300ë²ˆìœ¼ë¡œ êµ¬ë¶„ë˜ë©°, 2024ë…„ ê¸°ì¤€ìœ¼ë¡œ ì¼ë°˜íšŒê³„ 1ê°œ, íŠ¹ë³„íšŒê³„ 21ê°œ, ê¸°ê¸ˆ 68ê°œë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ ì‚¬ì—… ìš´ì˜ì— ëŒ€í•œ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  16%|â–ˆâ–‹        | 8/49 [13:52<1:04:52, 94.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ ì‚¬ì—…ì€ ê³ ë ¹ì´ë‚˜ ë…¸ì¸ì„± ì§ˆë³‘ìœ¼ë¡œ ì¼ìƒìƒí™œì„ í˜¼ìì„œâ€‹â€‹ ìˆ˜í–‰í•˜ê¸° ì–´ë ¤ìš´ ë…¸ì¸ ë“±ì—ê²Œ ì‹ ì²´ ë˜ëŠ” ê°€ì‚¬ í™œë™ ë“±ì„ ì œê³µí•˜ëŠ” ë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ì—â€‹â€‹ êµ­ê³ ì§€ì›ì„ í•˜ì—¬, íš¨ìœ¨ì ì¸ ì •ì±…ì¶”ì§„ìœ¼ë¡œ ë…¸í›„ì˜ ê±´ê°•ì¦ì§„ ë° ìƒí™œ ì•ˆì •ì„ ë„ëª¨í•˜ê³ â€‹â€‹ ê°€ì¡±ì˜ ë¶€ë‹´ì„ ì™„í™”í•˜ì—¬ êµ­ë¯¼ ì‚¶ì˜ ì§ˆì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ëª©ì ì…ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ ìš´ì˜ì§€ì›ì— ëŒ€í•œ ì‚¬ì—… ë‚´ìš©ì„ ì„¤ëª…í•´ì¤˜.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ ìš´ì˜ì§€ì›ì— ëŒ€í•œ ì‚¬ì—… ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: êµ­ê³ ì§€ì›ì„ ë°›ëŠ” ê¸°íƒ€ ì˜ë£Œê¸‰ì—¬ìˆ˜ê¸‰ê¶ŒìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  18%|â–ˆâ–Š        | 9/49 [15:12<1:00:04, 90.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ê¸°íƒ€ ì˜ë£Œê¸‰ì—¬ìˆ˜ê¸‰ê¶Œì ê¸‰ì—¬ë¹„ìš© êµ­ê°€ë¶€ë‹´ê¸ˆâ€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¥ê¸°ìš”ì–‘ë³´í—˜ê°€ì…ì ë° í”¼ë¶€ì–‘ìì˜ ìê²©ì·¨ë“ê³¼ ê´€ë ¨í•˜ì—¬ ì–´ë–¤ ë²•ë¥ ì„ ì¤€ìš©í•´ì•¼ í•˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ë²• ì œ4ì¡°(êµ­ê°€ ë° ì§€ë°©ìì¹˜ë‹¨ì²´ì˜ ì±…ë¬´ ë“±) 4êµ­ê°€ ë° ì§€ë°©ìì¹˜ë‹¨ì²´ëŠ” ì¥ê¸°ìš”ì–‘ê¸‰ì—¬ê°€ ì›í™œíˆ ì œê³µë  ìˆ˜ ìˆë„ë¡ ê³µë‹¨ì— í•„ìš”í•œ í–‰ì •ì  ë˜ëŠ” ì¬ì •ì  ì§€ì›ì„ í•  ìˆ˜ ìˆë‹¤.â€‹ë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ë²• ì œ11ì¡°(ì¥ê¸°ìš”ì–‘ë³´í—˜ê°€ì… ìê²© ë“±ì— ê´€í•œ ì¤€ìš©) 1ì¥ê¸°ìš”ì–‘ë³´í—˜ê°€ì…ìÂ·í”¼ë¶€ì–‘ìì˜ ìê²©ì·¨ë“Â·ìƒì‹¤, ì¥ê¸°ìš”ì–‘ë³´í—˜ë£Œ ë“±ì˜ ë‚©ë¶€Â·ì§•ìˆ˜ ë° ê²°ì†ì²˜ë¶„ ë“±ì— ê´€í•˜ì—¬ ì´ë¥¼ ì¤€ìš©í•œë‹¤.â€‹ë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ë²• ì œ35ì¡°ì˜2\n",
      "\n",
      "Question: ë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ë²•ì´ ì–¸ì œ ì œì •ë˜ê³  ê³µí¬ë˜ì—ˆë‚˜?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  20%|â–ˆâ–ˆ        | 10/49 [16:45<59:09, 91.02s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2007ë…„ 4ì›” 27ì¼ ì œì • ê³µí¬ë˜ì—ˆìŠµë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¥ê¸°ìš”ì–‘ì¸ì •ì ìˆ˜ ì™„í™”ê°€ ì–¸ì œ ì´ë£¨ì–´ì¡Œìœ¼ë©°, ì–´ë–¤ ë³€í™”ê°€ ìˆì—ˆë‚˜?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2012ë…„ 7ì›” 1ì¼ ë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ë²• ì‹œí–‰ë ¹ ê°œì •ìœ¼ë¡œ 3ë“±ê¸‰ ì¸ì •ì ìˆ˜ ì™„í™”(53ì ~75ì  â†’ 51ì ~75ì )â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¥ê¸°ìš”ì–‘ê¸°ê´€ ì§€ì •ê°±ì‹ ì œì˜ ë²•ì  ê·¼ê±°ê°€ ì–¸ì œ ë§ˆë ¨ë˜ì—ˆëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  22%|â–ˆâ–ˆâ–       | 11/49 [18:18<57:58, 91.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2018ë…„ 12ì›” 26ì¼, ã€Œë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ë²•ã€ ê°œì •ì•ˆì´ êµ­íšŒ ë³¸íšŒì˜ë¥¼ í†µê³¼í•˜ì—¬ 2023ë…„ 6ì›” 27ì¼ë¶€í„° ì‹œí–‰ë  ì˜ˆì •ì´ë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: 22.10ì›”ì— ìš”ì–‘ë³´í˜¸ì‚¬ 1ëª…ë‹¹ ì‹œì„¤ìˆ˜ê¸‰ì ì¸ë ¥ë°°ì¹˜ê¸°ì¤€ì´ ê°œì„ ëœ ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2022ë…„ 10ì›” 1ì¼ ì‹œí–‰ë˜ëŠ” ë…¸ì¸ì¥ê¸°ìš”ì–‘ë³´í—˜ë²• ì‹œí–‰ë ¹ ê°œì •ì•ˆì— ë”°ë¼ ìš”ì–‘ë³´í˜¸ì‚¬ 1ëª…ë‹¹ ì‹œì„¤ìˆ˜ê¸‰ì ì¸ë ¥ë°°ì¹˜ê¸°ì¤€ì´ 2.3ëª…ì—ì„œ 2.5ëª…ìœ¼ë¡œ ê°œì„ ë©ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì—ë„ˆì§€ ë°”ìš°ì²˜ ì œë„ì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      "Answering Questions:  24%|â–ˆâ–ˆâ–       | 12/49 [20:01<58:41, 95.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì—ë„ˆì§€ë°”ìš°ì²˜ ì œë„ëŠ” ì—ë„ˆì§€ì†Œì™¸ê³„ì¸µì˜ ì—ë„ˆì§€ë³µì§€ë¥¼ ìœ„í•´ ë„ì…ëœ ì œë„ì…ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—…ì˜ ì£¼ìš” ìˆ˜í˜œìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—…ì˜ ì£¼ìš” ìˆ˜í˜œìëŠ” ì—ë„ˆì§€ì†Œì™¸ê³„ì¸µì…ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: 2024ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—…ì˜ ì‚¬ì—…ì‹œí–‰ì£¼ì²´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  27%|â–ˆâ–ˆâ–‹       | 13/49 [22:10<1:03:16, 105.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2024ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—…ì˜ ì‚¬ì—…ì‹œí–‰ì£¼ì²´ëŠ” í•œêµ­ì—ë„ˆì§€ê³µë‹¨ì…ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: í•˜ì ˆê¸°ë°”ìš°ì²˜ì™€ ë™ì ˆê¸°ë°”ìš°ì²˜ì˜ 2024ë…„ ì˜ˆì‚° ê·œëª¨ëŠ” ê°ê° ì–¼ë§ˆì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2024ë…„ í•˜ì ˆê¸°ë°”ìš°ì²˜ ì˜ˆì‚°ì€ 190,963ë°±ë§Œì›, ë™ì ˆê¸°ë°”ìš°ì²˜ ì˜ˆì‚°ì€ 685,606ë°±ë§Œì›ì…ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: 2023ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—… ì˜ˆì‚°ì—ì„œ ì‚¬ì—…ìš´ì˜ë¹„ ì¤‘ ì—ë„ˆì§€ë³µì§€ í™ë³´ì— ì–¼ë§ˆê°€ í• ë‹¹ë˜ì—ˆë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  29%|â–ˆâ–ˆâ–Š       | 14/49 [24:48<1:10:46, 121.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2023ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—… ì˜ˆì‚°ì—ì„œ ì‚¬ì—…ìš´ì˜ë¹„ ì¤‘ ì—ë„ˆì§€ë³µì§€ í™ë³´ì— 328ë°±ë§Œì›ì´ í• ë‹¹ë˜ì—ˆìŠµë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: 2023ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—… ì˜ˆì‚°ì—ì„œ ì‚¬ì—…ìš´ì˜ë¹„ ì¤‘ ì‹œìŠ¤í…œ ê³ ë„í™”ì— ì–¼ë§ˆê°€ í• ë‹¹ë˜ì—ˆë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2023ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—… ì˜ˆì‚°ì—ì„œ ì‚¬ì—…ìš´ì˜ë¹„ ì¤‘ ì‹œìŠ¤í…œ ê³ ë„í™”ì— ì–¼ë§ˆê°€ í• ë‹¹ë˜ì—ˆëŠ”ì§€ì— ëŒ€í•œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: 2023ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—… ì˜ˆì‚°ì—ì„œ ì½œì„¼í„° ìš´ì˜ì— ì–¼ë§ˆê°€ í• ë‹¹ë˜ì—ˆë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  31%|â–ˆâ–ˆâ–ˆ       | 15/49 [27:16<1:13:11, 129.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2023ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—… ì˜ˆì‚°ì€ 1,872ë°±ë§Œì›ì…ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: 2023ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—… ì˜ˆì‚°ì—ì„œ íŒ¨ë„ì¡°ì‚¬ì— ì–¼ë§ˆê°€ í• ë‹¹ë˜ì—ˆë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2023ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—… ì˜ˆì‚°ì€ 1,349ë°±ë§Œì›ì…ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: 2023ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—… ì˜ˆì‚°ì—ì„œ ì—ë„ˆì§€ë°”ìš°ì²˜ ì „ë‹¬ì²´ê³„ êµ¬ì¶•ì— ì–¼ë§ˆê°€ í• ë‹¹ë˜ì—ˆë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  33%|â–ˆâ–ˆâ–ˆâ–      | 16/49 [29:42<1:13:55, 134.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2023ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—… ì˜ˆì‚°ì€ 1,872ë°±ë§Œì›ì…ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: 2023ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—… ì˜ˆì‚°ì—ì„œ ì£¼íƒê´€ë¦¬ê³µë‹¨ ìš´ì˜ì§€ì›ì— ì–¼ë§ˆê°€ í• ë‹¹ë˜ì—ˆë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2023ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—… ì˜ˆì‚°ì—ì„œ ì£¼íƒê´€ë¦¬ê³µë‹¨ ìš´ì˜ì§€ì›ì— 50ë°±ë§Œì›ì´ í• ë‹¹ë˜ì—ˆìŠµë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—…ì˜ í–¥í›„ ê¸°ëŒ€íš¨ê³¼ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  35%|â–ˆâ–ˆâ–ˆâ–      | 17/49 [32:03<1:12:47, 136.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—…ì€ ì—ë„ˆì§€ë³µì§€ ì‚¬ê°ì§€ëŒ€ì— ìˆëŠ” ì—ë„ˆì§€ì†Œì™¸ê³„ì¸µì—ê²Œ ì—ë„ˆì§€ì´ìš©ê¶Œì„ ì§€ê¸‰í•˜ì—¬ ì—ë„ˆì§€ë³µì§€ë¥¼ ì‹¤í˜„í•˜ëŠ” ì‚¬ì—…ì…ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—…ì— ëŒ€í•œ ì˜ˆë¹„íƒ€ë‹¹ì„±ì¡°ì‚¬ë¥¼ ì–´ë–¤ ì¡°ì‚¬ê¸°ê´€ì´ ìˆ˜í–‰í–ˆë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì˜ˆë¹„íƒ€ë‹¹ì„±ì¡°ì‚¬â€‹ëŠ”â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: 21ë…„ êµ­ì •ê°ì‚¬ì—ì„œ ì—ë„ˆì§€ ë°”ìš°ì²˜ ì‚¬ì—…ì— ëŒ€í•œ ì£¼ìš” ì§€ì ì‚¬í•­ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 18/49 [34:08<1:08:37, 132.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 21ë…„ êµ­ì •ê°ì‚¬ì—ì„œ ì§€ì ëœ ì£¼ìš” ì§€ì ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: 21ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—…ì— ëŒ€í•œ ê²°ì‚° ì§€ì ì‚¬í•­ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2021ë…„ ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—…ì€ 2020ë…„ í•˜ì ˆê¸° ì´ìƒê¸°ì˜¨ì— ë”°ë¥¸ ì „ê¸°ì‚¬ìš©ëŸ‰ í•˜ë½ìœ¼ë¡œ, ì‚¬íšŒë°°ë ¤ê³„ì¸µì— ëŒ€í•œ í• ì¸ì•¡ ê°ì†Œâ€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì—ë„ˆì§€ ë°”ìš°ì²˜ ì‚¬ì—…ì˜ í–¥í›„ ì¶”ì§„ë°©í–¥ ì¤‘ 'ì·¨ì•½ê³„ì¸µì˜ ì—ë„ˆì§€ ë¹„ìš© ë¶€ë‹´ ì™„í™”'ë¥¼ ìœ„í•œ ê³„íšì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 19/49 [36:19<1:06:08, 132.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì—ë„ˆì§€ë°”ìš°ì²˜ ì‚¬ì—…ì€ ì—ë„ˆì§€ë³µì§€ì˜ ì‚¬ê°ì§€ëŒ€ì— ìˆëŠ” ì—ë„ˆì§€ì†Œì™¸ê³„ì¸µì˜ ì—ë„ˆì§€ë¹„ìš© ë¶€ë‹´ì„ ì™„í™”í•˜ê¸° ìœ„í•œ ì‚¬ì—…ì…ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: í–‰ë³µì£¼íƒì¶œì ì‚¬ì—…ì€ ì–´ë–¤ ê·¼ê±°ë¡œ ì¶”ì§„ë˜ê³  ìˆëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: í–‰ë³µì£¼íƒì¶œì ì‚¬ì—…ì€ 2017ë…„ 11ì›” 29ì¼ ã€Œì£¼íƒë„ì‹œê¸°ê¸ˆë²•ã€ ê°œì •ìœ¼ë¡œ ê¸°ê¸ˆì˜ ì£¼íƒê³„ì • ì¶œì ê·¼ê±°ê°€ ë§ˆë ¨ë¨ì— ë”°ë¼ 2018ë…„ 1ì›” 1ì¼ ì‹œí–‰ëœ ì‚¬ì—…ìœ¼ë¡œ, 2024ë…„ê¹Œì§€ ì´ 2.2ë§Œí˜¸ë¥¼ ê³µê¸‰í•  ê³„íšì´ë‹¤.â€‹í–‰ë³µì£¼íƒì¶œì ì‚¬ì—…ì€ ê¸°ê¸ˆì˜ ì¶œì, ì¶œì—°, ìœµì, ë³´ì¡° ë“±ì˜ ë°©ë²•ìœ¼ë¡œ ì¶”ì§„ë˜ë©°, ê¸°ê¸ˆì˜ ì¶œì, ì¶œì—°, ìœµì, ë³´ì¡° ë“±ì˜ ê²½ìš°ì—ëŠ” ê¸°ê¸ˆìš´ìš©ê³„íšì— ë”°ë¼ ìš´ìš©ëœë‹¤.â€‹í–‰\n",
      "\n",
      "Question: í–‰ë³µì£¼íƒì¶œì ì‚¬ì—…ì€ ì–´ë–¤ ëª©ì ìœ¼ë¡œ ì‹œí–‰ë˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/49 [38:36<1:04:38, 133.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: í–‰ë³µì£¼íƒì¶œì ì‚¬ì—…ì€ ë„ì‹¬ ë‚´ ë‹¤ì–‘í•œ ë¶€ì§€ë¥¼ í™œìš©í•˜ì—¬ í–‰ë³µì£¼íƒì„ ê³µê¸‰í•˜ëŠ” ì‚¬ì—…ì…ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: í–‰ë³µì£¼íƒì¶œì ì‚¬ì—…ì˜ ì£¼ìš” ìˆ˜í˜œìëŠ” ëˆ„êµ¬ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: í–‰ë³µì£¼íƒì¶œì ì‚¬ì—…ì˜ ì£¼ìš” ìˆ˜í˜œìëŠ” ëŒ€í•™ìƒ, ì‚¬íšŒì´ˆë…„ìƒ, ì‹ í˜¼ë¶€ë¶€, ê³ ë ¹ì ë° ì£¼ê±°ì·¨ì•½ê³„ì¸µì´ë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: í–‰ë³µì£¼íƒì¶œì ì‚¬ì—…ì˜ ì‚¬ì—…ë¹„ ì¶”ì´ëŠ” ì–´ë– í•œê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/49 [40:55<1:03:11, 135.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: í–‰ë³µì£¼íƒì¶œì ì‚¬ì—…ì˜ ì‚¬ì—…ë¹„ ì¶”ì´ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: í–‰ë³µì£¼íƒì¶œì ì‚¬ì—…ì˜ ì‚¬ì—…ì‹œí–‰ì£¼ì²´ëŠ” ëˆ„êµ¬ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: í–‰ë³µì£¼íƒì¶œì ì‚¬ì—…ì˜ ì‚¬ì—…ì‹œí–‰ì£¼ì²´ëŠ” í•œêµ­í† ì§€ì£¼íƒê³µì‚¬(LH)ì´ë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: êµ­ê³ ë³´ì¡°ì‚¬ì—…ì˜ ë³´ì¡°ìœ¨ì€ ì–´ë– í•œ ê¸°ì¤€ì— ë”°ë¼ ìš´ìš©ë˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/49 [42:45<57:30, 127.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: êµ­ê³ ë³´ì¡°ì‚¬ì—…ì˜ ë³´ì¡°ìœ¨ì€ ì§€ë°©êµë¶€ì„¸ì™€ êµ­ê³ ë³´ì¡°ê¸ˆìœ¼ë¡œ êµ¬ë¶„ë˜ë©°, 2024ë…„ ê¸°ì¤€ìœ¼ë¡œ ì§€ë°©êµë¶€ì„¸ â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: í”„ë‘ìŠ¤ì˜ ì¬ì •ì¡°ì •ì œë„ì—ì„œ ìµœê·¼ ê°•ì¡°ë˜ëŠ” í˜•í‰êµë¶€ê¸ˆì€ ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: í”„ë‘ìŠ¤ì˜ ì§€ë°©ì¬ì •ì¡°ì •ì œë„ëŠ” ì§€ë°©êµë¶€ì„¸ ì¤‘ ë³´í†µêµë¶€ì„¸ì²˜ëŸ¼ ì£¼ë¯¼ ìˆ˜ì™€ ë©´ì ìœ¼ë¡œ ë°°ë¶„ì˜ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ìŒâ€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì§€ë°©ì¬ì •ì¡°ì •ì œë„ì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 23/49 [44:48<54:40, 126.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì§€ë°©ìì¹˜ë‹¨ì²´ ê°„ ì¬ì •ë ¥ ê²©ì°¨ì˜ ì‹œì •, ì§€ì—­ ê°„ ì™¸ë¶€ íš¨ê³¼ì˜ ë‚´ë¶€í™”ë¥¼ í†µí•œ ì§€ë°©ê³µê³µì¬ ê³µê¸‰, ì¤‘ì•™ì •ë¶€ì˜ ìœ„ì„ì‚¬ë¬´ì— ëŒ€í•œ ë¹„ìš© ë¶€ë‹´ ë“±ì„ ëª©ì ìœ¼ë¡œ ì¬ì •ì„ ì¡°ì •í•˜ëŠ” ì¼ë ¨ì˜ ì¡°ì¹˜ë¥¼ ì˜ë¯¸í•¨.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: êµ­ì œì ìœ¼ë¡œ ì„±ê³¼ì¤‘ì‹¬ ì¬ì •ê´€ë¦¬ ê°•í™” ì›€ì§ì„ì´ í™•ì‚°ëœ ì‹œê¸°ëŠ” ì–¸ì œì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 200ë…„ëŒ€ í›„ë°˜ ê¸ˆìœµìœ„ê¸°ë¡œ ì„±ê³¼ì¤‘ì‹¬ ì¬ì •ê´€ë¦¬ ê°•í™” ì›€ì§ì„ì´ êµ­ì œì ìœ¼ë¡œ í™•ì‚°ë¨ì— ë”°ë¼ 2007ë…„ ê¸°ì¤€, â€‹70% ì´ìƒì˜ OECD êµ­ê°€ì—ì„œ ì˜ˆê²°ì‚° ë¬¸ì„œì— ë¹„ì¬ë¬´ì  ì„±ê³¼ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆë‹¤.â€‹â€‹ìš°ë¦¬ë‚˜ë¼ë„ 2006ë…„ 4ëŒ€ ì¬ì •ê°œí˜(êµ­ê°€ì¬ì •ìš´ìš©ê³„íš, ì´ì•¡ë°°ë¶„ììœ¨í¸ì„±ì˜ˆì‚°, ì¬ì •ì„±ê³¼ê´€ë¦¬, ë””ì§€í„¸ì˜ˆì‚°íšŒê³„ì‹œìŠ¤í…œ)ì„ í†µí•´ â€‹â€‹í”„ë¡œê·¸ë¨ ì˜ˆì‚°ì œë„ë¥¼ ê·¼ê°„ìœ¼ë¡œ í•˜ëŠ” ì¬ì •ì‚¬ì—… ì„±ê³¼ê´€ë¦¬ì œë„ë¥¼ ì •ì°©ì‹œì¼œ ìš´ì˜ ì¤‘ì´ë‹¤.â€‹â€‹2018ë…„ í•µì‹¬ì‚¬ì—…í‰ê°€\n",
      "\n",
      "Question: í•œêµ­ì˜ ì¬ì •ì‚¬ì—… ì„±ê³¼ê´€ë¦¬ì œë„ëŠ” ì–´ë– í•œ ë²•ì„ í†µí•´ ìš´ì˜ë˜ê³  ìˆìœ¼ë©°, ì„±ê³¼ê´€ë¦¬ ê¸°ë³¸ê³„íšê³¼ ì¶”ì§„ê³„íšì€ ì–´ë–»ê²Œ ì˜ë¬´í™”ë˜ì—ˆëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 24/49 [45:18<40:32, 97.31s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: í•œêµ­ì˜ ì¬ì •ì‚¬ì—… ì„±ê³¼ê´€ë¦¬ì œë„ëŠ” 2007ë…„ ã€Œêµ­ê°€ì¬ì •ë²•ã€ ì‹œí–‰ ì´í›„ ìµœì†Œí•œì˜ ë²• ì¡°í•­ìœ¼ë¡œ ìš´ì˜ë˜ì–´ ì˜¤ë‹¤, 2021ë…„ 12ì›” ë²• ê°œì •ì„ í†µí•´ ë³„ë„ì˜ ì¥(ç« ) ì‹ ì„¤ë¡œ ê°œë… ë° ì²´ê³„ ëª…í™•í™”â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: í•µì‹¬ì¬ì •ì‚¬ì—… ì„±ê³¼ê´€ë¦¬ì œë„ë¥¼ ì•ˆì°©ì‹œí‚¤ê¸° ìœ„í•´ í•„ìš”í•œ ë…¸ë ¥ê³¼ ì„±ê³¼ ì •ë³´ë¥¼ í•™ìŠµì˜ ë„êµ¬ë¡œ í™œìš©í•˜ëŠ” ë°©ì•ˆì€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2024ë…„ ì¤‘ì•™ì •ë¶€ ì¬ì •ì²´ê³„ëŠ” ì˜ˆì‚°(ì¼ë°˜Â·íŠ¹ë³„íšŒê³„)ê³¼ ê¸°ê¸ˆìœ¼ë¡œ êµ¬ë¶„ë˜ë©°, 2024ë…„ ê¸°ì¤€ìœ¼ë¡œ ì¼ë°˜íšŒê³„ 1ê°œ, íŠ¹ë³„íšŒê³„ 21ê°œ, ê¸°ê¸ˆ 68ê°œë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì‚¬íšŒë³´í—˜ ì‚¬ê°ì§€ëŒ€ ë°œìƒì˜ ì£¼ìš” ì›ì¸ê³¼ ì´ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ë¬¸ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/49 [45:48<30:52, 77.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì‚¬íšŒë³´í—˜ ê°€ì…ì€ ë²•ì  ì˜ë¬´ì´ë‚˜ ì‚¬ì—…ì£¼ì˜ ë¹„ìš©ì ˆê°, ë³´í—˜ ê°€ì…ì— ë”°ë¥¸ ê·¼ë¡œìì˜ ì‹¤ì§ˆ ê°€ì²˜ë¶„ ì†Œë“ ê°ì†Œ ë“± í˜„ì‹¤ì  ì´ìœ ë¡œ ê³ ìš© ì·¨ì•½ê³„ì¸µ ë° ì†Œê·œëª¨ ì‚¬ì—…ì¥ì¼ìˆ˜ë¡ ì‚¬íšŒë³´í—˜ ê°€ì…ì´ ì €ì¡°í•©ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì²­ë…„ì¼ìë¦¬ë„ì•½ì¥ë ¤ê¸ˆì€ ì–´ë–¤ ëŒ€ìƒì„ ì§€ì›í•˜ë©°, ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì§€ì›ë˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì²­ë…„ì¼ìë¦¬ë„ì•½ì¥ë ¤ê¸ˆì€ ë§Œ 19~34ì„¸ì˜ ì·¨ì—…ì• ë¡œì²­ë…„(â€™22ë…„ ê¸°ì¤€, 15~34ì„¸ ì²­ë…„ ì¤‘ 15~29ì„¸ ì²­ë…„ 70.1%, 30~34ì„¸ ì²­ë…„ 29.9%)ì„ ìš°ì„ ì§€ì›ëŒ€ìƒê¸°ì—…ì—ì„œ ì •ê·œì§ìœ¼ë¡œ ì±„ìš© í›„ 6ê°œì›” ì´ìƒ ê³ ìš©ìœ ì§€í•˜ëŠ” ê²½ìš° ìµœì¥ 2ë…„ê°„ ì§€ì›11)(í•œì‹œì‚¬ì—…, â€™22~â€™24ë…„)â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ìˆ˜ì§ì  ì¬ì •ì¡°ì •ì œë„ì™€ ìˆ˜í‰ì  ì¬ì •ì¡°ì •ì œë„ì˜ ì°¨ì´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/49 [47:17<30:54, 80.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ìˆ˜ì§ì  ì¬ì •ì¡°ì •ì œë„ëŠ” ì¤‘ì•™ì •ë¶€ì™€ ì§€ë°©ì •ë¶€ ê°„(ìˆ˜ì§ì ) ë˜ëŠ” ì§€ë°©ì •ë¶€ ìƒí˜¸ ê°„(ìˆ˜í‰ì )ì— ì¬ì •ì„ ì¬ë°°ë¶„í•˜ëŠ” â€‹ì§€ë°©ì¬ì •ì¡°ì •ì œë„ë¥¼ ìš´ì˜â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì§€ë°©ì¬ì •ì¡°ì •ì œë„ëŠ” ì–´ë–¤ ëª©ì ì„ ê°€ì§€ê³  ìˆë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì§€ë°©ìì¹˜ë‹¨ì²´ ê°„ ì¬ì •ë ¥ ê²©ì°¨ì˜ ì‹œì •, ì§€ì—­ ê°„ ì™¸ë¶€ íš¨ê³¼ì˜ ë‚´ë¶€í™”ë¥¼ í†µí•œ ì§€ë°©ê³µê³µì¬ ê³µê¸‰, ì¤‘ì•™ì •ë¶€ì˜ ìœ„ì„ì‚¬ë¬´ì— ëŒ€í•œ ë¹„ìš© ë¶€ë‹´ ë“±ì„ ëª©ì ìœ¼ë¡œ ì¬ì •ì„ ì¡°ì •í•˜ëŠ” ì¼ë ¨ì˜ ì¡°ì¹˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¤‘ì•™-ì§€ë°© ê°„ ì¬ì •ì¡°ì •ì œë„ì—ì„œ ì–´ë–¤ ì¬ì›ì„ ì´ì „í•˜ì—¬ ìˆ˜ì§ì  ì¬ì • ë¶ˆê· í˜•ì„ í•´ì†Œí•˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 27/49 [48:35<29:20, 80.03s/it]c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì¤‘ì•™-ì§€ë°© ê°„ ì¬ì •ì¡°ì •ì œë„ì˜ ê°œë…ê³¼ ëª©í‘œâ€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¤‘ì•™ì •ë¶€ì˜ ì˜ˆì‚°í¸ì„±ì€ ì–´ë–¤ ì¬ì› ë°°ë¶„ ë¬¸ì œë¥¼ ê²°ì •í•˜ë©°, ì¤‘ì•™-ì§€ë°© ê°„ ì¬ì •ì¡°ì •ì œë„ë¥¼ í†µí•´ ì–´ë–¤ ì¬ì›ì„ ì´ì „í•˜ê³ , ì´ì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€?\n",
      "Answer: ì¤‘ì•™ì •ë¶€ì˜ ì˜ˆì‚°í¸ì„±ì€ ì§€ë°©êµë¶€ì„¸ì™€ êµ­ê³ ë³´ì¡°ê¸ˆì˜ ì¬ì› ë°°ë¶„ ë¬¸ì œë¥¼ ê²°ì •í•˜ë©°, ì¤‘ì•™-ì§€ë°© ê°„ ì¬ì •ì¡°ì •ì œë„ë¥¼ í†µí•´ ì§€ë°©êµë¶€ì„¸ì™€ êµ­ê³ ë³´ì¡°ê¸ˆì˜ ì¬ì›ì„ ì´ì „í•˜ê³ , ì´ì˜ ëª©ì ì€ ì§€ë°©êµë¶€ì„¸ì™€ êµ­ê³ ë³´ì¡°ê¸ˆì˜ ì¬ì› ë°°ë¶„ì„ í†µí•´ ì§€ë°©êµë¶€ì„¸ì™€ êµ­ê³ ë³´ì¡°ê¸ˆì˜ ì¬ì›ì„ ì´ì „í•˜ê³ , ì´ì˜ ëª©ì ì€ ì§€ë°©êµë¶€ì„¸ì™€ êµ­ê³ ë³´ì¡°ê¸ˆì˜ ì¬ì› ë°°ë¶„ì„ í†µí•´ ì§€ë°©êµë¶€ì„¸ì™€ êµ­ê³ ë³´ì¡°ê¸ˆì˜ ì¬ì›ì„ ì´ì „í•˜ê³ , ì´ì˜ ëª©ì ì€ ì§€ë°©êµë¶€ì„¸ì™€ êµ­ê³ ë³´ì¡°ê¸ˆì˜ ì¬ì› ë°°ë¶„ì„ í†µí•´ ì§€ë°©\n",
      "\n",
      "Question: ì¬ì •ì‚¬ì—… ì„±ê³¼ê´€ë¦¬ì œë„ì˜ í•„ìš”ì„±ì´ ëŒ€ë‘ëœ ì‹œê¸°ì™€ í•œêµ­ì˜ ì¬ì •ì‚¬ì—… ì„±ê³¼ê´€ë¦¬ì œë„ê°€ ì–´ë–¤ ë²•ì— ê·¼ê±°í•˜ì—¬ ìš´ì˜ë˜ê³  ìˆëŠ”ì§€ ì„¤ëª…í•˜ì‹œì˜¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 28/49 [49:35<25:53, 73.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 200ë…„ëŒ€ í›„ë°˜ë¶€í„° ì¬ì •ì‚¬ì—… ì„±ê³¼ê´€ë¦¬ì— ëŒ€í•œ êµ­ì œì  ë…¼ì˜ê°€ í™œë°œíˆ ì§„í–‰ë˜ì—ˆê³ , 2007ë…„ ã€Œêµ­ê°€ì¬ì •ë²•ã€ ì‹œí–‰â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì²­ë…„ì¼ìë¦¬ë„ì•½ì¥ë ¤ê¸ˆì€ ì–´ë–¤ ëŒ€ìƒì„ ì§€ì›í•˜ë©°, ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì§€ì›ë˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì²­ë…„ì¼ìë¦¬ë„ì•½ì¥ë ¤ê¸ˆì€ ë§Œ 19~34ì„¸ì˜ ì·¨ì—…ì• ë¡œì²­ë…„(â€™22ë…„ ê¸°ì¤€, 15~34ì„¸ ì²­ë…„ ì¤‘ 15~29ì„¸ ì²­ë…„ 70.1%, 30~34ì„¸ ì²­ë…„ 29.9%)ì„ ìš°ì„ ì§€ì›ëŒ€ìƒê¸°ì—…ì—ì„œ ì •ê·œì§ìœ¼ë¡œ ì±„ìš© í›„ 6ê°œì›” ì´ìƒ ê³ ìš©ìœ ì§€í•˜ëŠ” ê²½ìš° ìµœì¥ 2ë…„ê°„ ì§€ì›11)(í•œì‹œì‚¬ì—…, â€™22~â€™24ë…„)â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¬ì •ì„±ê³¼ê´€ë¦¬ì œë„ëŠ” ì–´ë–¤ ì¸¡ë©´ì—ì„œ êµ­ì •ìš´ì˜ê³¼ ì—°ê²°ë˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 29/49 [51:02<25:54, 77.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì¬ì •ì„±ê³¼ê´€ë¦¬ì œë„ëŠ” ì „ëµëª©í‘œì™€ ìš°ì„ ìˆœìœ„ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì¬ì •ì‚¬ì—…ì„ ì¬êµ¬ì¡°í™”í•œë‹¤ëŠ” ì ì—ì„œ êµ­ì •ìš´ì˜ê³¼ ì—°ê²°â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì„±ê³¼ê´€ë¦¬ì˜ ì‹¤íš¨ì„± ê°•í™”ë¥¼ ìœ„í•´ ì •ë¶€ê°€ ì·¨í•œ ì¡°ì¹˜ëŠ” ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2023ë…„ ì¬ì •ì‚¬ì—… ì„±ê³¼ê´€ë¦¬ ì œë„ ì „ë©´ ê°œí¸â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¬ì •ì„±ê³¼ê´€ë¦¬ ê´€ë ¨ ì£¼ìš” ìŸì ì€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/49 [52:26<25:12, 79.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì¬ì •ì„±ê³¼ê´€ë¦¬ì œë„ ê´€ë ¨ ì£¼ìš” ìŸì ì€ ë‹¤ìŒê³¼ ê°™ìŒâ€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¬ì •ì„±ê³¼ê´€ë¦¬ê°€ ì™œ ì¤‘ìš”í•œê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì¬ì •ì„±ê³¼ê´€ë¦¬ëŠ” ì¬ì •ì‚¬ì—…ì˜ ì„±ê³¼ì™€ ì±…ì„ì„±ì„ ì œê³ í•˜ê³ , ì¬ì •íˆ¬ì…ì˜ íš¨ìœ¨ì„±ê³¼ íš¨ê³¼ì„±ì„ í–¥ìƒâ€‹â€‹ì‹œí‚¤ê¸° ìœ„í•œ ì œë„â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¬ì •ì„±ê³¼ê´€ë¦¬ëŠ” ë¬´ì—‡ì„ ëª©í‘œë¡œ í•˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/49 [53:21<21:42, 72.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì¬ì •ì„±ê³¼ê´€ë¦¬ëŠ” ì¬ì •ì‚¬ì—…ì˜ ê¸°íšì—ì„œ ì§‘í–‰, í™˜ë¥˜, ì¢…ë£Œì— ì´ë¥´ëŠ” ì „ ì£¼ê¸°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•˜ì—¬ â€‹íš¨ìœ¨ì  ì¬ì • ìš´ìš©ì„ ë’·ë°›ì¹¨í•˜ê³ , ê´€ë ¨ ì •ë³´ë¥¼ êµ­ë¯¼ì—ê²Œ ê³µê°œí•˜ì—¬ ì±…ì„ì„±ì„ í™•ë³´í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì–´ë–¤ êµ­ì œê¸°êµ¬ë“¤ì´ ì‚¬ì—…ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì‚°ì„ ë‚˜ëˆ„ì–´ ì„±ê³¼ ì •ë³´ë¥¼ ìƒì‚°í•˜ê³  ìˆëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: OECD, World Bank, UN ë“± êµ­ì œê¸°êµ¬ë“¤ì€ ì‚¬ì—…ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì‚°ì„ ë‚˜ëˆ„ì–´ ì„±ê³¼ ì •ë³´ë¥¼ ìƒì‚°í•˜ê³  ìˆìŒâ€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¬ì •ì„±ê³¼ê´€ë¦¬ì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 32/49 [54:14<18:52, 66.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì¬ì •ì„±ê³¼ê´€ë¦¬ëŠ” ì •ë¶€ ì¬ì •ì˜ íˆ¬ëª…ì„±, ì±…ì„ì„±, íš¨ìœ¨ì„±, íš¨ê³¼ì„±, ì˜ˆì‚°ì¬ë¶„ë°° ë“±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ì œë„â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: 2021ë…„ ã€Œêµ­ê°€ì¬ì •ë²•ã€ ê°œì •ìœ¼ë¡œ ì–´ë–¤ ê·œì •ì´ ì‹ ì„¤ë˜ì—ˆëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2021ë…„ ã€Œêµ­ê°€ì¬ì •ë²•ã€ ê°œì •ìœ¼ë¡œ, ë™ ë²•ì— ì˜í•œ ì¬ì •ì‚¬ì—… í‰ê°€ì™€ ê°œë³„ ë²•ë ¹ì— ë”°ë¼ ì‹¤ì‹œë˜ëŠ” í‰ê°€ ëŒ€ìƒ ì¤‘ë³µì´ ìµœì†Œí™”ë˜ë„ë¡ í•˜ëŠ” ê·œì •ì„ ì‹ ì„¤í•˜ì—¬, ì¬ì •ì„±ê³¼ê´€ë¦¬ë¥¼ ìœ„í•œ ì¬ì •ì‚¬ì—… í‰ê°€ì™€ ê°œë³„ ë²•ë ¹ì— ë”°ë¼ ì‹¤ì‹œë˜ëŠ” í‰ê°€ ê°„ì˜ ê´€ê³„ë¥¼ ìµœì´ˆë¡œ ê·œì •í•˜ì˜€ìŠµë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì„±ê³¼ê´€ë¦¬ì œë„ëŠ” ì§€ì¶œ êµ¬ì¡°ì¡°ì •ì„ ìœ„í•´ ì–´ë–¤ ë°©í–¥ìœ¼ë¡œ ì¶”ì§„ë˜ê³  ìˆëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 33/49 [55:32<18:38, 69.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2021ë…„ ì„±ê³¼ê´€ë¦¬ì œë„ëŠ” 2020ë…„ ëŒ€ë¹„ ì§€ì¶œ êµ¬ì¡°ì¡°ì •ì„ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì´ ì¶”ì§„â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¬ì •ì‚¬ì—… ììœ¨í‰ê°€ì˜ ëª©ì ì€ ë¬´ì—‡ì´ë©°, ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì œë„ ê°œì„ ì´ ì´ë£¨ì–´ì¡ŒëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì¬ì •ì‚¬ì—… ììœ¨í‰ê°€ëŠ” 2006ë…„ ã€Œêµ­ê°€ì¬ì •ë²•ã€ ê°œì •ìœ¼ë¡œ ë„ì…ëœ ì œë„ì´ë‹¤. 2006ë…„ ã€Œêµ­ê°€ì¬ì •ë²•ã€ ê°œì •ìœ¼ë¡œ 2007ë…„ë¶€í„° 3ë…„ ì£¼ê¸°ë¡œ ì¬ì •ì‚¬ì—…ì— ëŒ€í•œ í‰ê°€ë¥¼ ì‹¤ì‹œí•˜ì˜€ìœ¼ë©°, 2011ë…„ë¶€í„°ëŠ” 2015ë…„ê¹Œì§€ 5ë…„ ì£¼ê¸°ë¡œ ì¬ì •ì‚¬ì—…ì— ëŒ€í•œ í‰ê°€ë¥¼ ì‹¤ì‹œí•˜ì˜€ë‹¤. 2016ë…„ë¶€í„°ëŠ” 2018ë…„ê¹Œì§€ 3ë…„ ì£¼ê¸°ë¡œ ì¬ì •ì‚¬ì—…ì— ëŒ€í•œ í‰ê°€ë¥¼ ì‹¤ì‹œí•˜ì˜€ë‹¤. 2018ë…„ ã€Œêµ­ê°€ì¬ì •ë²•ã€ ê°œì •ìœ¼ë¡œ \n",
      "\n",
      "Question: 2016ë…„ ì¬ì •ì„±ê³¼ê´€ë¦¬ì œë„ì˜ í™˜ë¥˜ ê°œì„ ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 34/49 [56:23<16:06, 64.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2016ë…„ ì¬ì •ì„±ê³¼ê´€ë¦¬ì œë„ ê°œì„ ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: 2018ë…„ë„ì— ì¬ì •ì„±ê³¼ê´€ë¦¬ì œë„ ê°œì„ ì‚¬í•­ê³¼, ì´ë¡œ ì¸í•´ ì–´ë–¤ íš¨ê³¼ê°€ ë°œìƒí–ˆëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2018ë…„ ã€Œêµ­ê°€ì¬ì •ë²•ã€ ê°œì •ìœ¼ë¡œ, ì¬ì •ì„±ê³¼ê´€ë¦¬ì œë„ì˜ ì„±ê³¼ê´€ë¦¬ ê°•í™”â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¬ì •ì‚¬ì—… ììœ¨í‰ê°€ì˜ ì „ë©´ ê°œí¸ì„ í†µí•´ ì–´ë–¤ ì¤‘ì  ì¶”ì§„ê³¼ì œê°€ ì œì‹œë˜ì—ˆëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35/49 [57:25<14:48, 63.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ë‹µë³€:â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¬ì •ì„±ê³¼ê´€ë¦¬ì œë„ì˜ ì¤‘ìš”ì„±ê³¼ êµ­ì •ìš´ì˜ê³¼ì˜ ì—°ê²°ì„±ì€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì¬ì •ì„±ê³¼ê´€ë¦¬ì œë„ëŠ” ì¬ì •ì‚¬ì—…ì˜ ê¸°íšì—ì„œ ì§‘í–‰, í™˜ë¥˜, ì¢…ë£Œì— ì´ë¥´ëŠ” ì „ ì£¼ê¸°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•˜ì—¬ â€‹íš¨ìœ¨ì  ì¬ì • ìš´ìš©ì„ ë’·ë°›ì¹¨í•˜ê³ , ê´€ë ¨ ì •ë³´ë¥¼ êµ­ë¯¼ì—ê²Œ ê³µê°œí•˜ì—¬ ì±…ì„ì„±ì„ í™•ë³´í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¬ì •ì„±ê³¼ê´€ë¦¬ì²´ê³„ ê°•í™”ë¥¼ ìœ„í•´ ì •ë¶€ê°€ ì–´ë–¤ ì œë„ë¥¼ ì œì‹œí–ˆìœ¼ë©°, ì¬ì •ì„±ê³¼ê´€ë¦¬ëŠ” ë¬´ì—‡ì„ ëª©í‘œë¡œ í•˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/49 [58:43<14:41, 67.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì¬ì •ì„±ê³¼ê´€ë¦¬ëŠ” ì •ë¶€ ì¬ì •ì˜ íˆ¬ëª…ì„±, ì±…ì„ì„±, íš¨ìœ¨ì„±, íš¨ê³¼ì„±, ì˜ˆì‚°ì¬ë¶„ë°° ë“±ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¬ì •ì„±ê³¼ê´€ë¦¬ëŠ” ì–´ë–¤ ê³¼ì •ì—ì„œ ìˆ˜í–‰ë˜ë©°, ë¬´ì—‡ì„ ì¦ì§„í•˜ê¸° ìœ„í•´ í™œë™í•˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì¬ì •ì„±ê³¼ê´€ë¦¬ëŠ” ì¬ì •ì‚¬ì—…ì˜ ê¸°íšì—ì„œ ì§‘í–‰, í™˜ë¥˜, ì¢…ë£Œì— ì´ë¥´ëŠ” ì „ ì£¼ê¸°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•˜ì—¬ â€‹â€‹íš¨ìœ¨ì  ì¬ì • ìš´ìš©ì„ ë’·ë°›ì¹¨í•˜ê³ , ê´€ë ¨ ì •ë³´ë¥¼ êµ­ë¯¼ì—ê²Œ ê³µê°œí•˜ì—¬ ì±…ì„ì„±ì„ í™•ë³´í•˜ëŠ” ê²ƒì„ ì˜ë¯¸â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¬ì •ì„±ê³¼ê´€ë¦¬ì˜ ëª©ì ê³¼ ìš°ë¦¬ë‚˜ë¼ì˜ ì¬ì •ì„±ê³¼ê´€ë¦¬ì œë„ê°€ í”„ë¡œê·¸ë¨ ì˜ˆì‚°ì œë„ë¡œ ì „í™˜ëœ ì‹œê¸°ëŠ”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 37/49 [59:41<12:59, 64.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì¬ì •ì„±ê³¼ê´€ë¦¬ì˜ ëª©ì ì€ ì¬ì •ì‚¬ì—…ì˜ ê¸°íšì—ì„œ ì§‘í–‰, í™˜ë¥˜, ì¢…ë£Œì— ì´ë¥´ëŠ” ì „ ì£¼ê¸°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•˜ì—¬ íš¨ìœ¨ì  ì¬ì • ìš´ìš©ì„ ë’·ë°›â€‹ì¹¨í•˜ê³ , ê´€ë ¨ ì •ë³´ë¥¼ êµ­ë¯¼ì—ê²Œ ê³µê°œí•˜ì—¬ ì±…ì„ì„±ì„ í™•ë³´í•˜ëŠ” ê²ƒì„ ì˜ë¯¸â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: 2007ë…„ê³¼ 2021ë…„ì— ê°ê° ã€Œêµ­ê°€ì¬ì •ë²•ã€ì´ ê°œì •ë˜ë©´ì„œ ì„±ê³¼ê´€ë¦¬ ì œë„ëŠ” ì–´ë–»ê²Œ ê°•í™”ë˜ê³  êµ¬ì²´í™”ë˜ì—ˆìœ¼ë©°, ì´ ê°œì •ì˜ ì£¼ëœ ëª©ì ì€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2007ë…„ ã€Œêµ­ê°€ì¬ì •ë²•ã€ ì‹œí–‰ìœ¼ë¡œ ê³¼ê±°ì— ë‹¨ë°œì ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ì„±ê³¼ê´€ë¦¬ ì œë„ë¥¼ ì¢…í•©í•˜ì—¬, ì„±ê³¼ê´€ë¦¬ì˜ ê¸°ë³¸ ë‹¨ìœ„, ì„±ê³¼ ì¸¡ì •ê³¼ ë³´ê³ ë¥¼ ìœ„í•œ ì²´ê³„ í™•ë¦½â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¬ì •ì‚¬ì—… ììœ¨í‰ê°€ì˜ ëª©ì ê³¼ ì œë„ ê°œì„  ë°©ì‹ì€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 38/49 [1:01:03<12:50, 70.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì¬ì •ì‚¬ì—… ììœ¨í‰ê°€ëŠ” ì¬ì •ì‚¬ì—…ì˜ ì„±ê³¼ê´€ë¦¬ë¥¼ ìœ„í•´ 2006ë…„ë¶€í„° ì‹¤ì‹œí•˜ê³  ìˆëŠ” ì œë„ì´ë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: 2015ë…„ ì´ì „ê³¼ 2016ë…„ì— ì¬ì •ì„±ê³¼ í‰ê°€ ê²°ê³¼ ì²˜ë¦¬ ë°©ì‹ê³¼ í™˜ë¥˜ ê°œì„  ë°©ì‹ì€ ì–´ë–»ê²Œ ë‹¬ë¼ì¡ŒëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2015ë…„ ì´ì „ì—ëŠ” í‰ê°€ ëŒ€ìƒ ì‚¬ì—…ì˜ ë²”ìœ„, í‰ê°€ ì£¼ê¸°, ìƒìœ„ í‰ê°€ ë°©ì‹ ë“±ì—ì„œ ì§€ì†ì ì¸ ì œë„ ê°œì„ ì´ ì´ë£¨ì–´ì¡Œâ€‹ìœ¼ë©°, 2016~2017ë…„ì—ëŠ” ì—°êµ¬ê°œë°œì‚¬ì—…ì„ í¬í•¨ì‹œí‚¤ê³  í‰ê°€ ì£¼ê¸°ë¥¼ ì „ ì‚¬ì—…ì— ê±¸ì³ ë§¤ë…„ í‰ê°€í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³€ê²½í•œ í†µâ€‹í•©ì¬ì •ì‚¬ì—… í‰ê°€ì œë„ ì‹œí–‰â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¬ì •ê´€ë¦¬ì‹œìŠ¤í…œ êµ¬ì¶•ê³¼ ì„±ê³¼ê´€ë¦¬ ê°œí¸ì„ ì¶”ì§„í•˜ëŠ” ì£¼ëœ ëª©ì ì€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 39/49 [1:01:32<09:38, 57.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì¬ì •ê´€ë¦¬ì‹œìŠ¤í…œ êµ¬ì¶•ê³¼ ì„±ê³¼ê´€ë¦¬ ê°œí¸ì„ ì¶”ì§„í•˜ëŠ” ì£¼ëœ ëª©ì ì€ ì¬ì •ì„±ê³¼ê´€ë¦¬ì˜ ì‹¤íš¨ì„±ì„ ì œê³ í•˜ê¸° ìœ„â€‹í•œ ê²ƒì´ë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ìš°ë¦¬ë‚˜ë¼ì—ì„œëŠ” ì–¸ì œë¶€í„° ë°œìƒì£¼ì˜ ê¸°ì¤€ì„ ì ìš©í•œ êµ­ê°€ê²°ì‚°ë³´ê³ ì„œì—ì„œ ìš°ë°œë¶€ì±„ë¥¼ ë³´ê³ í•˜ê³  ìˆëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2018ë…„ ã€Œì¶©ë‹¹ë¶€ì±„, ìš°ë°œë¶€ì±„, ìš°ë°œìì‚° íšŒê³„ì²˜ë¦¬ì§€ì¹¨ã€ ê°œì • ì´í›„ë¶€í„° êµ­ê°€ê²°ì‚°ë³´ê³ ì„œì—ì„œ ìš°ë°œë¶€ì±„ë¥¼ ì¬ë¬´ì œí‘œ(ì¬ì •ìƒíƒœí‘œ)ì—ì„œ ì¸ì‹í•˜ì§€ ì•ŠëŠ”ë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ìš°ë°œë¶€ì±„ ê´€ë ¨ ì£¼ìš” ìŸì ì€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40/49 [1:02:56<09:51, 65.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ìš°ë°œë¶€ì±„ì˜ ê´€ë¦¬ëŠ” ì™œ ì¤‘ìš”í•œ ì´ìŠˆë¡œ ì—¬ê²¨ì§€ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 1. ìš°ë°œë¶€ì±„ëŠ” ë¯¸ë˜ì˜ ë‹¤ì–‘í•œ ì˜ì œì˜ë¬´(constructive obligation)ë¥¼ í¬ê´„í•˜ëŠ” ê°œë…ìœ¼ë¡œ, ê³µê³µë¶€ë¬¸ì˜ ì¬ì •ê±´ì „ì„±, ì¬ì •ìœ„ê¸° ê´€ë¦¬ ë“± ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì¤‘ìš”í•˜ê²Œ ë‹¤ë¤„ì ¸ì•¼ í•  í•„ìš”ì„±ì´ ìˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ìš°ë°œë¶€ì±„ì™€ ë¶€ì±„ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/49 [1:04:20<09:29, 71.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ë°œìƒì£¼ì˜ì™€ í˜„ê¸ˆì£¼ì˜ì˜ ì°¨ì´ëŠ” ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ë°œìƒì£¼ì˜(accrual basis)ë€ â€˜ê²½ì œì  ê±°ë˜ê°€ ë°œìƒí•˜ëŠ” ì‹œì â€™ì— ê±°ë˜ë¥¼ ê¸°ë¡í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, â€˜í˜„ê¸ˆì„ ìˆ˜ì·¨í•˜ê±°ë‚˜ ì§€ê¸‰í•œ ì‹œì â€™ì— ê±°ë˜ë¥¼ ê¸°ë¡í•˜ëŠ” ë°©ì‹ì¸ í˜„ê¸ˆì£¼ì˜(cash â€‹â€‹basis)ì™€ ì°¨ì´ê°€ ìˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì±„ë¬´ì§€ì†ê°€ëŠ¥ì„±ë¶„ì„ì€ ì–´ë–¤ ëª©ì ì„ ê°€ì§€ê³  ë„ì…ë˜ì—ˆëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 42/49 [1:05:44<08:45, 75.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ì±„ë¬´ì§€ì†ê°€ëŠ¥ì„±ë¶„ì„ì€ ì¬ì •ìœ„í—˜ì„ ì¸¡ì •í•˜ê¸° ìœ„í•œ ìˆ˜ë‹¨ìœ¼ë¡œ ë„ì…ë˜ì—ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì˜ì œì˜ë¬´ë€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 1) \u0007â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: êµ­ì œí†µí™”ê¸°ê¸ˆì´ ì¬ì •í†µê³„ ì‘ì„±ì˜ êµ­ì œê¸°ì¤€ì„ ì œì‹œí•˜ê¸° ìœ„í•´ ë°œê°„í•œ ë§¤ë‰´ì–¼ì€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 43/49 [1:06:45<07:05, 70.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: êµ­ì œí†µí™”ê¸°ê¸ˆì€ ì¬ì •í†µê³„ ì‘ì„±ì˜ êµ­ì œê¸°ì¤€ì„ ì œì‹œí•˜ê¸° ìœ„í•´ 1986ë…„ ì¬ì •í†µê³„ ë§¤ë‰´ì–¼(Government Finance Statistics Manual, GFSM)ì„ ì²˜ìŒ ë°œê°„í•˜ì˜€ìœ¼ë©°, ì´í›„ 2001ë…„ê³¼ 2014ë…„ ì´ 2ì°¨ë¡€ì˜ ê°œì •ì´ ìˆì—ˆë‹¤. ì¬ì •í†µê³„ ë§¤ë‰´ì–¼ì˜ ë°œê°„(ë˜ëŠ” ê°œì •) ì—°ë„ì— ë”°ë¼ ê°ê° GFSM1986, GFSM2001, GFSM2014ë¡œ ì§€ì¹­ëœë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ê³„ë¥˜ì¤‘ì¸ ì†Œì†¡ì‚¬ê±´ì´ë€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ê³„ë¥˜ì¤‘ì¸ ì†Œì†¡ì‚¬ê±´ì€ ì†Œì†¡ì´ ì§„í–‰ ì¤‘ì´ê±°ë‚˜ ì†Œì†¡ì´ ì¢…ê²°ë˜ì—ˆìœ¼ë‚˜ ì•„ì§ íŒê²°ì´ ë‚˜ì§€ ì•Šì€ ì‚¬ê±´ì„ ë§í•œë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ìµœì†Œìš´ì˜ìˆ˜ì…ë³´ì¥(BTO ë“±) ì œë„ë€ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 44/49 [1:08:15<06:22, 76.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ìµœì†Œìš´ì˜ìˆ˜ì…ë³´ì¥ ì œë„ë€ ì£¼ë¡œ BTO ë¯¼ê°„íˆ¬ìì‚¬ì—… ì¤‘ ì‹¤ì‹œí˜‘ì•½ì„œ ìƒ ì¶”ì • ìˆ˜ì…ë³´ë‹¤ ì‹¤ì œ ìˆ˜ì…ì´ ë¯¸ì¹˜ì§€ ëª»í•˜ëŠ” ê²½ìš° ì •ë¶€ê°€ ìµœì†Œìš´ì˜ìˆ˜ì…ì„ ë³´ì¥í•´ ì£¼ëŠ” ì œë„ë¥¼ ë§í•¨16)â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ìš°ë°œë¶€ì±„ì— ëŒ€í•œ ë‚´ìš©ìœ¼ë¡œ ëŒ€í‘œì ìœ¼ë¡œ ì–´ë–¤ ì‚¬í•­ì´ í•´ë‹¹ë˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: GFSM2014ì—ì„œëŠ” ìš°ë°œë¶€ì±„ë¥¼ ì–´ë–»ê²Œ êµ¬ë¶„í•˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/49 [1:09:38<05:14, 78.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: GFSM2014ì—ì„œëŠ” ëª…ì‹œì  ìš°ë°œë¶€ì±„ì™€ ì•”ë¬µì  ìš°ë°œë¶€ì±„ë¡œ êµ¬ë¶„í•˜ê³  ìˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: GFSMì€ ëª‡ ì°¨ë¡€ì˜ ê°œì •ì„ ê±°ì³¤ìœ¼ë©°, ì–´ë– í•œ ëª©ì ìœ¼ë¡œ GFSM 2001ì´ ê°œì •ë˜ì—ˆëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: GFSMì€ 1986ë…„ ì²« ë°œê°„ ì´ë˜ í˜„ì¬ê¹Œì§€ ì´ 2ì°¨ë¡€(2001ë…„, 2014ë…„)ì˜ ê°œì •ì´ ìˆì—ˆë‹¤. íŠ¹íˆ, GFSM 2001ì€ ì „ë©´ ê°œì •ì„ í†µí•´ í˜„ì¬ì˜ ë°œìƒì£¼ì˜ ê¸°ì¤€ GFSì²´ê³„ë¥¼ â€‹êµ¬ì¶•í•˜ì˜€ìœ¼ë©°, GFSM2014ëŠ” SNA, PSDS ë“± ë‹¤ë¥¸ êµ­ì œí†µê³„ê¸°ì¤€ê³¼ ë¶€í•©í•˜ë„ë¡ ë” êµ¬ì²´í™”í–ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: í‘œì¤€í™” ë³´ì¦ì´ë€ ë¬´ì—‡ì¸ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/49 [1:11:09<04:06, 82.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: í‘œì¤€í™” ë³´ì¦ì´ë€ í‘œì¤€í™” ë³´ì¦ì€ í†µìƒ ì•„ì£¼ ì ì€ ê¸ˆì•¡ì— ëŒ€í•´ íšì¼ì  ì¡°ê±´ìœ¼ë¡œ ëŒ€ê·œëª¨ë¡œ ë°œí–‰í•˜ëŠ” ë³´ì¦ì„ ë§í•˜ë©°, ìˆ˜ì¶œ(ë¬´ì—­)ì‹ ìš© ë³´ì¦, í™˜ë³´ì¦, ë‹¤ì–‘í•œâ€‹ì¤‘ íŒŒìƒìƒí’ˆí‰ê°€ì†ìµìœ¼ë¡œ ì²˜ë¦¬í•˜ë©°, ì£¼ì„ ì‚¬í•­ì—ë„ íŒŒìƒìƒí’ˆ ë‚´ì—­ì„ ê¸°ì¬14)â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: í‘œì¤€í™” ë³´ì¦ì—ì„œ ê³µê³µë¶€ë¬¸ì˜ ìš°ë°œë¶€ì±„ëŠ” ì–´ë–»ê²Œ ì¸ì‹ë˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ìš°ë°œë¶€ì±„ëŠ” ì¼ë°˜ì ìœ¼ë¡œ â€˜ëª…ì‹œì â€™ê³¼ â€˜ì•”ë¬µì â€™ìœ¼ë¡œ êµ¬ë¶„ëœë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ì¬ì •ì •ì±…ì—ì„œ ê³µì ë³´ì¦ì±„ë¬´ì™€ ë‹¤ë¥¸ ì¼íšŒì„± ë³´ì¦ì€ ì–´ë–»ê²Œ êµ¬ë¶„ë˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 47/49 [1:12:38<02:48, 84.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ê³µì ë³´ì¦ì±„ë¬´ëŠ” ë³´ì¦ì¸ì´ ê¸°íƒ€ ê³µê³µë¶€ë¬¸ê³¼ ë¯¼ê°„ë¶€ë¬¸ ë‹¨ìœ„ ê¸°ì¡´ ì±„ë¬´ì˜ ì›ë¦¬ê¸ˆ ìƒí™˜ì„ ë³´ì¦í•œë‹¤ëŠ” ì ì—ì„œ ë‹¤ ë¥¸ ì¼íšŒì„± ë³´ì¦ê³¼ëŠ” êµ¬ë¶„ë˜ë©°, ì¬ì •ì •ì±… ë° ë¶„ì„ì—ì„œ ì¤‘ìš”â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ë¯¸ë˜ì‚¬íšŒë³´ì¥ê¸‰ì—¬ì— ëŒ€í•œ ìˆœì˜ë¬´ë€ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ë¯¸ë˜ì‚¬íšŒë³´ì¥ê¸‰ì—¬ì— ëŒ€í•œ ìˆœì˜ë¬´ë€ ë¯¸ë˜ì‚¬íšŒë³´ì¥ê¸‰ì—¬ì— ëŒ€í•œ ìˆœì˜ë¬´ë€ ë¯¸ë˜ì‚¬íšŒë³´ì¥ê¸‰ì—¬ì— ëŒ€í•œ ìˆœì˜ë¬´ë€ ë¯¸ë˜ì‚¬íšŒë³´ì¥ê¸‰ì—¬ì— ëŒ€í•œ ìˆœì˜ë¬´ë€ ë¯¸ë˜ì‚¬íšŒë³´ì¥ê¸‰ì—¬ì— ëŒ€í•œ ìˆœì˜ë¬´ë€ ë¯¸ë˜ì‚¬íšŒë³´ì¥ê¸‰ì—¬ì— ëŒ€í•œ ìˆœì˜ë¬´ë€ ë¯¸ë˜ì‚¬íšŒë³´ì¥ê¸‰ì—¬ì— ëŒ€í•œ ìˆœì˜ë¬´ë€ ë¯¸ë˜ì‚¬íšŒë³´ì¥ê¸‰ì—¬ì— ëŒ€í•œ ìˆœì˜ë¬´ë€ ë¯¸ë˜ì‚¬íšŒë³´ì¥ê¸‰ì—¬ì— ëŒ€í•œ ìˆœì˜ë¬´ë€ ë¯¸ë˜ì‚¬íšŒë³´ì¥ê¸‰ì—¬ì— ëŒ€í•œ ìˆœì˜ë¬´ë€ ë¯¸ë˜ì‚¬íšŒë³´ì¥ê¸‰ì—¬ì— ëŒ€í•œ ìˆœì˜ë¬´ë€ ë¯¸ë˜ì‚¬íšŒë³´ì¥ê¸‰ì—¬ì— ëŒ€í•œ ìˆœì˜ë¬´ë€ ë¯¸ë˜ì‚¬íšŒë³´ì¥ê¸‰ì—¬ì— ëŒ€í•œ ìˆœì˜\n",
      "\n",
      "Question: êµ­ê°€ê²°ì‚°ë³´ê³ ì„œì™€ ì§€ë°©ìì¹˜ë‹¨ì²´ íšŒê³„ê¸°ì¤€ì—ì„œ ìš°ë°œë¶€ì±„ì— ëŒ€í•œ ìš©ì–´ ë° íšŒê³„ì²˜ë¦¬ê°€ ì–´ë–»ê²Œ ë‹¤ë¥¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 48/49 [1:14:00<01:23, 83.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: êµ­ê°€ê²°ì‚°ë³´ê³ ì„œëŠ” êµ­ê°€íšŒê³„ê¸°ì¤€ì— ë”°ë¼ ìš°ë°œë¶€ì±„ë¥¼ ì˜ë¬´ ì´í–‰ì„ ìœ„í•´ ìì›ì´ ìœ ì¶œë  ê°€ëŠ¥ì„±ì´ í¬ë°•í•˜ì§€ ì•Šì€ í•œ ì£¼ì„5 â€˜ìš°ë°œì‚¬í•­ ë° ì•½ì •ì‚¬í•­â€™ì— ê³µì‹œí•˜ê³  ìˆìœ¼ë©°, ì¬ì •ìƒíƒœí‘œì—ëŠ” ì¸ì‹í•˜ì§€ ì•ŠìŒ12)â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ìš°ë°œë¶€ì±„ë€ ë¬´ì—‡ì´ë©°, ê·¸ ê´€ë¦¬ê°€ ì™œ ì¤‘ìš”í•œê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ìš°ë°œë¶€ì±„ë€ ë¯¸ë˜ì˜ íŠ¹ì • ì‚¬ê±´(ë“¤)ì´ ì¼ì–´ë‚˜ì§€ ì•ŠëŠ” í•œ ë°œìƒí•˜ì§€ ì•ŠëŠ” ì˜ë¬´ë¡œ, í•˜ë‚˜ ë˜ëŠ” ê·¸ ì´ìƒì˜ ì¡°ê±´ì´ ì¶©ì¡±ë˜ì–´ì•¼ ê¸ˆìœµê±°ë˜ë¡œ ì¸ì‹ëœë‹¤ëŠ” ì ì—ì„œ â€˜ë¶€ì±„â€™ì™€ ì°¨ì´6)â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n",
      "Question: ë³´ì¦ì´ë€ ë¬´ì—‡ì´ë©°, ì–´ë–¤ í˜•íƒœì˜ ë³´ì¦ì´ ì¬ì •ìƒíƒœí‘œì— ë¶€ì±„ë¡œ ê¸°ë¡ë˜ëŠ”ê°€? ë˜í•œ í‘œì¤€í™” ë³´ì¦ì´ë€ ë¬´ì—‡ì´ë©°, ì–´ë–¤ ëª©ì ìœ¼ë¡œ ë°œí–‰ë˜ëŠ”ê°€?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkdru\\anaconda3\\envs\\python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Answering Questions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [1:15:33<00:00, 92.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ë³´ì¦ì´ë€ ì±„ë¬´ìê°€ ì±„ë¬´ë¥¼ ì´í–‰í•˜ì§€ ëª»í•  ê²½ìš°ì— ì±„ë¬´ìì—ê²Œ ëŒ€ì‹ í•˜ì—¬ ì±„ë¬´ë¥¼ ì´í–‰í•˜ëŠ” ê²ƒì„ ë§í•©ë‹ˆë‹¤.â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def normalize_string(s):\n",
    "    \"\"\"ìœ ë‹ˆì½”ë“œ ì •ê·œí™”\"\"\"\n",
    "    return unicodedata.normalize('NFC', s)\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…\"\"\"\n",
    "    context = \"\"\n",
    "    for doc in docs:\n",
    "        context += doc.page_content\n",
    "        context += '\\n'\n",
    "    return context\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "results = []\n",
    "\n",
    "# ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì„¤ì •\n",
    "batch_size = 2  # ì›í•˜ëŠ” ë°°ì¹˜ í¬ê¸°ë¡œ ì„¤ì •\n",
    "\n",
    "# DataFrameì˜ ê° í–‰ì— ëŒ€í•´ ì²˜ë¦¬\n",
    "for start in tqdm(range(0, len(df), batch_size), desc=\"Answering Questions\"):\n",
    "    # í˜„ì¬ ë°°ì¹˜ ì„ íƒ\n",
    "    batch_rows = df.iloc[start:start + batch_size]\n",
    "\n",
    "    # ë°°ì¹˜ ë‚´ì˜ ê° í–‰ ì²˜ë¦¬\n",
    "    for _, row in batch_rows.iterrows():\n",
    "        # ì†ŒìŠ¤ ë¬¸ìì—´ ì •ê·œí™”\n",
    "        source = normalize_string(row['Source'])\n",
    "        question = row['Question']\n",
    "\n",
    "        # ì •ê·œí™”ëœ í‚¤ë¡œ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰\n",
    "        normalized_keys = {normalize_string(k): v for k, v in pdf_databases.items()}\n",
    "        retriever = normalized_keys[source]['retriever']\n",
    "\n",
    "        # RAG ì²´ì¸ êµ¬ì„±\n",
    "        template = \"\"\"\n",
    "        ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì—­í• ì„ í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì˜¬ë°”ë¥¸ ë‹µë³€ì„ í•˜ì„¸ìš”.\n",
    "        ì§ˆë¬¸ì— ë‹µí•  ë•ŒëŠ” ë¶€ê°€ì ì¸ ì •ë³´ ì—†ì´ ë¬¼ì–´ë³¸ ê²ƒì—ë§Œ ë‹µ í•´ ì£¼ì‹­ì‹œì˜¤.\n",
    "        \n",
    "        ë‹µë³€í•  ë•Œì—ëŠ” ë‹¤ìŒ ì˜ˆì‹œì™€ ê°™ì´ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì‹­ì‹œì˜¤\n",
    "        [ì˜ˆì‹œ1]\n",
    "        2024ë…„ ì¤‘ì•™ì •ë¶€ ì¬ì •ì²´ê³„ëŠ” ì˜ˆì‚°(ì¼ë°˜Â·íŠ¹ë³„íšŒê³„)ê³¼ ê¸°ê¸ˆìœ¼ë¡œ êµ¬ë¶„ë˜ë©°, 2024ë…„ ê¸°ì¤€ìœ¼ë¡œ ì¼ë°˜íšŒê³„ 1ê°œ, íŠ¹ë³„íšŒê³„ 21ê°œ, ê¸°ê¸ˆ 68ê°œë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "        [ì˜ˆì‹œ2]\n",
    "        2024ë…„ ì¤‘ì•™ì •ë¶€ì˜ ì˜ˆì‚° ì§€ì¶œì€ ì¼ë°˜íšŒê³„ 356.5ì¡°ì›, 21ê°œ íŠ¹ë³„íšŒê³„ 81.7ì¡°ì›ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "        [ì˜ˆì‹œ3]\n",
    "        ê¸°ê¸ˆì€ ì˜ˆì‚°ê³¼ êµ¬ë¶„ë˜ëŠ” ì¬ì •ìˆ˜ë‹¨ìœ¼ë¡œì„œ ì¬ì •ìš´ì˜ì˜ ì‹ ì¶•ì„±ì„ ê¸°í•  í•„ìš”ê°€ ìˆì„ ë•Œ, ì •ë¶€ê°€ í¸ì„±í•˜ê³  êµ­íšŒì—ì„œ ì‹¬ì˜ãƒ»ì˜ê²°í•œ ê¸°ê¸ˆìš´ìš©ê³„íšì— ì˜í•´ ìš´ìš©ë©ë‹ˆë‹¤.\n",
    "        [ì˜ˆì‹œ4]\n",
    "        ì‚¬íšŒë³´ì¥ê¸°ì—¬ê¸ˆì€ êµ­ê°€ê°€ êµ­ë¯¼ì˜ ì•ˆì •ì ì¸ ì‚¶ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ ìš´ì˜í•˜ëŠ” ì‚¬íšŒë³´ì¥ì œë„ì˜ ì¬ì •ì„ ë§ˆë ¨í•˜ê¸° ìœ„í•´ ì§•ìˆ˜í•˜ëŠ” ê¸ˆì•¡ì…ë‹ˆë‹¤. ì´ ê¸°ì—¬ê¸ˆì€ êµ­ë¯¼ì˜ ë…¸í›„, ì‹¤ì—…, ì§ˆë³‘, ì¥ì•  ë“± ë‹¤ì–‘í•œ ì‚¬íšŒì  ìœ„í—˜ìœ¼ë¡œë¶€í„° ë³´í˜¸í•˜ê¸° ìœ„í•œ ëª©ì ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ì—°ê¸ˆ, ê±´ê°•ë³´í—˜, ê³ ìš©ë³´í—˜ ë“±ì˜ ë‹¤ì–‘í•œ ì‚¬íšŒë³´ì¥ í”„ë¡œê·¸ë¨ì— í•„ìš”í•œ ìê¸ˆìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ êµ­ë¯¼ ê°œê°œì¸ì´ ê²½ì œì , ì‚¬íšŒì  ì–´ë ¤ì›€ì— ì§ë©´í–ˆì„ ë•Œ í•„ìš”í•œ ì§€ì›ì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.\n",
    "        \n",
    "        ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”\n",
    "        \n",
    "        [ì •ë³´]\n",
    "        {context}\n",
    "\n",
    "        ì§ˆë¬¸: {question}\n",
    "        ë‹µë³€:\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "        # RAG ì²´ì¸ ì •ì˜\n",
    "        rag_chain = (\n",
    "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        # ë‹µë³€ ì¶”ë¡ \n",
    "        print(f\"Question: {question}\")\n",
    "        full_response = rag_chain.invoke(question)\n",
    "\n",
    "        print(f\"Answer: {full_response}\\n\")\n",
    "\n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        results.append({\n",
    "            \"Source\": row['Source'],\n",
    "            \"Source_path\": row['Source_path'],\n",
    "            \"Question\": question,\n",
    "            \"Answer\": full_response\n",
    "        })\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# ì œì¶œìš© ìƒ˜í”Œ íŒŒì¼ ë¡œë“œ\n",
    "submit_df = pd.read_csv(\"./sample_submission.csv\")\n",
    "\n",
    "# ìƒì„±ëœ ë‹µë³€ì„ ì œì¶œ DataFrameì— ì¶”ê°€\n",
    "submit_df['Answer'] = [item['Answer'] for item in results]\n",
    "submit_df['Answer'] = submit_df['Answer'].fillna(\"ë°ì´ì½˜\")     # ëª¨ë¸ì—ì„œ ë¹ˆ ê°’ (NaN) ìƒì„± ì‹œ ì±„ì ì— ì˜¤ë¥˜ê°€ ë‚  ìˆ˜ ìˆìŒ [ ì£¼ì˜ ]\n",
    "\n",
    "# ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "submit_df.to_csv(\"./baseline_submission.csv\", encoding='UTF-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì œì¶œìš© ìƒ˜í”Œ íŒŒì¼ ë¡œë“œ\n",
    "submit_df = pd.read_csv(\"./sample_submission.csv\")\n",
    "\n",
    "# ìƒì„±ëœ ë‹µë³€ì„ ì œì¶œ DataFrameì— ì¶”ê°€\n",
    "submit_df['Answer'] = [item['Answer'] for item in results]\n",
    "submit_df['Answer'] = submit_df['Answer'].fillna(\"ë°ì´ì½˜\")     # ëª¨ë¸ì—ì„œ ë¹ˆ ê°’ (NaN) ìƒì„± ì‹œ ì±„ì ì— ì˜¤ë¥˜ê°€ ë‚  ìˆ˜ ìˆìŒ [ ì£¼ì˜ ]\n",
    "\n",
    "# ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "submit_df.to_csv(\"./baseline_submission.csv\", encoding='UTF-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
